<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection System</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        /* Glass effect and custom styling */
        .glass-effect {
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.18);
            padding: 20px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        }

        body {
            min-height: 100vh;
            background: linear-gradient(45deg, #6a11cb, #2575fc);
            padding: 20px;
        }

        #video-container {
            position: relative;
            margin: auto;
            width: fit-content;
        }

        #face-canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .loading-spinner {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1000;
        }

        .user-data {
            margin-top: 20px;
        }

        .detection-controls {
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Loading Spinner -->
        <div class="loading-spinner text-white" id="loader">
            <div class="d-flex align-items-center">
                <strong>Loading models...</strong>
                <div class="spinner-border ms-3" role="status"></div>
            </div>
        </div>

        <div class="row">
            <!-- Video Feed and Detection Section -->
            <div class="col-lg-8 mb-4">
                <div class="glass-effect">
                    <div id="video-container">
                        <video id="video" width="640" height="480" autoplay muted></video>
                        <canvas id="face-canvas" width="640" height="480"></canvas>
                    </div>
                    <div class="detection-controls">
                        <button class="btn btn-primary me-2" id="startBtn">Start Detection</button>
                        <button class="btn btn-danger me-2" id="stopBtn">Stop Detection</button>
                        <button class="btn btn-success" id="captureBtn">Capture Face</button>
                    </div>
                </div>
            </div>

            <!-- Registration Form Section -->
            <div class="col-lg-4">
                <div class="glass-effect">
                    <h3 class="text-white mb-4">Register Face</h3>
                    <form id="registrationForm">
                        <div class="mb-3">
                            <input type="text" class="form-control" id="name" placeholder="Full Name" required>
                        </div>
                        <div class="mb-3">
                            <input type="email" class="form-control" id="email" placeholder="Email" required>
                        </div>
                        <div class="mb-3">
                            <input type="text" class="form-control" id="id" placeholder="ID Number" required>
                        </div>
                        <button type="submit" class="btn btn-primary w-100">Register</button>
                    </form>
                </div>

                <!-- Registered Users Section -->
                <div class="glass-effect user-data mt-4">
                    <h4 class="text-white mb-3">Registered Users</h4>
                    <div id="userList" class="list-group">
                        <!-- User entries will be added here dynamically -->
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Required Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>

    <script>
        // Global variables
        let isDetecting = false;
        let stream = null;
        const registeredUsers = [];

        // DOM Elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('face-canvas');
        const context = canvas.getContext('2d');
        const loader = document.getElementById('loader');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const captureBtn = document.getElementById('captureBtn');
        const registrationForm = document.getElementById('registrationForm');
        const userList = document.getElementById('userList');

        // Load face-api.js models
        async function loadModels() {
            try {
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights'),
                    faceapi.nets.faceLandmark68Net.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights'),
                    faceapi.nets.faceRecognitionNet.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights')
                ]);
                loader.style.display = 'none';
            } catch (error) {
                console.error('Error loading models:', error);
                alert('Error loading face detection models. Please refresh the page.');
            }
        }

        // Start video stream
        async function startVideo() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (error) {
                console.error('Error accessing camera:', error);
                alert('Unable to access camera. Please check permissions.');
            }
        }

        // Face detection function
        async function detectFaces() {
            if (!isDetecting) return;

            const detections = await faceapi.detectAllFaces(
                video,
                new faceapi.TinyFaceDetectorOptions()
            ).withFaceLandmarks();

            // Clear previous drawings
            context.clearRect(0, 0, canvas.width, canvas.height);

            // Draw detections
            detections.forEach(detection => {
                // Draw face box
                context.strokeStyle = '#00ff00';
                context.lineWidth = 2;
                context.strokeRect(
                    detection.detection.box.x,
                    detection.detection.box.y,
                    detection.detection.box.width,
                    detection.detection.box.height
                );

                // Draw landmarks
                const landmarks = detection.landmarks;
                context.fillStyle = '#00ff00';
                for (const point of landmarks.positions) {
                    context.beginPath();
                    context.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                    context.fill();
                }
            });

            requestAnimationFrame(detectFaces);
        }

        // Event Listeners
        startBtn.addEventListener('click', async () => {
            isDetecting = true;
            detectFaces();
        });

        stopBtn.addEventListener('click', () => {
            isDetecting = false;
            context.clearRect(0, 0, canvas.width, canvas.height);
        });

        captureBtn.addEventListener('click', () => {
            const captureCanvas = document.createElement('canvas');
            captureCanvas.width = video.videoWidth;
            captureCanvas.height = video.videoHeight;
            captureCanvas.getContext('2d').drawImage(video, 0, 0);
            
            // You can save this image or use it for face recognition
            const imageData = captureCanvas.toDataURL('image/png');
            console.log('Face captured:', imageData);
        });

        registrationForm.addEventListener('submit', (e) => {
            e.preventDefault();
            const userData = {
                name: document.getElementById('name').value,
                email: document.getElementById('email').value,
                id: document.getElementById('id').value,
                timestamp: new Date().toLocaleString()
            };

            registeredUsers.push(userData);
            updateUserList();
            registrationForm.reset();
        });

        // Update user list in UI
        function updateUserList() {
            userList.innerHTML = registeredUsers.map(user => `
                <div class="list-group-item">
                    <h6>${user.name}</h6>
                    <small class="text-muted">ID: ${user.id}</small><br>
                    <small class="text-muted">Registered: ${user.timestamp}</small>
                </div>
            `).join('');
        }

        // Initialize
        loadModels().then(startVideo);
    </script>
</body>
</html>
